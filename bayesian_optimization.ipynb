{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efbdbe5",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75fab278",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,accuracy_score,explained_variance_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import plot_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.base import clone\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import make_scorer\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e916c57",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af1a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RobustNN, self).__init__()\n",
    "        self.feature_weights = nn.Parameter(torch.ones(input_dim)) \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.feature_weights\n",
    "        return self.net(x)\n",
    "\n",
    "def loss_fn_with_l1(output, target, model, l1_lambda=0.01):\n",
    "    mse_loss = nn.MSELoss()(output, target)\n",
    "    l1_penalty = l1_lambda * torch.norm(model.feature_weights, p=1)\n",
    "    return mse_loss + l1_penalty\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=1000, patience=60, l1_lambda=0.01, lr=1e-3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch_X).squeeze()\n",
    "            loss = loss_fn_with_l1(preds, batch_y, model, l1_lambda)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for val_X, val_y in val_loader:\n",
    "                val_preds = model(val_X).squeeze()\n",
    "                val_loss = loss_fn_with_l1(val_preds, val_y, model, l1_lambda)\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "\n",
    "        # print(f\"Epoch {epoch+1:03d} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                # print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # 可视化 loss 曲线\n",
    "    # plt.plot(train_loss_history, label='Train Loss')\n",
    "    # plt.plot(val_loss_history, label='Val Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.title(\"Training and Validation Loss\")\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader, y_scaler):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            output = model(X_batch).squeeze()\n",
    "            predictions.append(output.cpu().numpy())\n",
    "            targets.append(y_batch.cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(predictions)\n",
    "    trues = np.concatenate(targets)\n",
    "\n",
    "    preds_real = y_scaler.inverse_transform(preds.reshape(-1, 1)).ravel()\n",
    "    trues_real = y_scaler.inverse_transform(trues.reshape(-1, 1)).ravel()\n",
    "\n",
    "    mae = mean_absolute_error(trues_real, preds_real)\n",
    "    mse = mean_squared_error(trues_real, preds_real)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(trues_real, preds_real)\n",
    "\n",
    "\n",
    "    # print(\"\\n=== 测试集评估结果 ===\")\n",
    "    # print(f\"MAE: {mae:.4f}\")\n",
    "    # print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "\n",
    "    return preds_real, trues_real "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30f80dd",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85217c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fe</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Ni</th>\n",
       "      <th>Mn</th>\n",
       "      <th>Al</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Co</th>\n",
       "      <th>Epit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.203058</td>\n",
       "      <td>0.236246</td>\n",
       "      <td>0.239013</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.025238</td>\n",
       "      <td>0.066468</td>\n",
       "      <td>0.226276</td>\n",
       "      <td>356.611982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.042621</td>\n",
       "      <td>0.028618</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>0.035668</td>\n",
       "      <td>324.940857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.077745</td>\n",
       "      <td>0.131589</td>\n",
       "      <td>0.139919</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.141893</td>\n",
       "      <td>-405.018555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.174752</td>\n",
       "      <td>0.220172</td>\n",
       "      <td>0.220218</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>0.200640</td>\n",
       "      <td>106.186977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.204421</td>\n",
       "      <td>0.239786</td>\n",
       "      <td>0.239522</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>0.051741</td>\n",
       "      <td>0.228763</td>\n",
       "      <td>423.067719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.233464</td>\n",
       "      <td>0.255418</td>\n",
       "      <td>0.260141</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.041972</td>\n",
       "      <td>0.107491</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>626.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.306684</td>\n",
       "      <td>0.306073</td>\n",
       "      <td>0.311860</td>\n",
       "      <td>0.030913</td>\n",
       "      <td>0.087726</td>\n",
       "      <td>0.192010</td>\n",
       "      <td>0.301496</td>\n",
       "      <td>861.663879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fe          Cr          Ni          Mn          Al          Cu  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean     0.203058    0.236246    0.239013    0.003701    0.025238    0.066468   \n",
       "std      0.042621    0.028618    0.029026    0.004025    0.022540    0.054250   \n",
       "min      0.077745    0.131589    0.139919    0.000040    0.000039    0.000538   \n",
       "25%      0.174752    0.220172    0.220218    0.001064    0.005027    0.018572   \n",
       "50%      0.204421    0.239786    0.239522    0.002220    0.018842    0.051741   \n",
       "75%      0.233464    0.255418    0.260141    0.004766    0.041972    0.107491   \n",
       "max      0.306684    0.306073    0.311860    0.030913    0.087726    0.192010   \n",
       "\n",
       "               Co        Epit  \n",
       "count  500.000000  500.000000  \n",
       "mean     0.226276  356.611982  \n",
       "std      0.035668  324.940857  \n",
       "min      0.141893 -405.018555  \n",
       "25%      0.200640  106.186977  \n",
       "50%      0.228763  423.067719  \n",
       "75%      0.255375  626.818359  \n",
       "max      0.301496  861.663879  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"generated_samples_robust.xlsx\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b46c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Epit'])\n",
    "y = df['Epit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "42759532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fe</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Ni</th>\n",
       "      <th>Mn</th>\n",
       "      <th>Al</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Co</th>\n",
       "      <th>E_M-M</th>\n",
       "      <th>Gibbs free energy of oxide formation_Aver</th>\n",
       "      <th>Energy of ionization second_Aver</th>\n",
       "      <th>Epit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.223816</td>\n",
       "      <td>0.227380</td>\n",
       "      <td>0.228819</td>\n",
       "      <td>3.304442e-02</td>\n",
       "      <td>1.863189e-02</td>\n",
       "      <td>4.050260e-02</td>\n",
       "      <td>0.227805</td>\n",
       "      <td>81.367155</td>\n",
       "      <td>-88.989191</td>\n",
       "      <td>1651.587129</td>\n",
       "      <td>232.402195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.049817</td>\n",
       "      <td>0.030970</td>\n",
       "      <td>0.036191</td>\n",
       "      <td>6.694506e-02</td>\n",
       "      <td>3.530871e-02</td>\n",
       "      <td>6.545965e-02</td>\n",
       "      <td>0.034336</td>\n",
       "      <td>3.386451</td>\n",
       "      <td>30.019819</td>\n",
       "      <td>24.654049</td>\n",
       "      <td>280.525059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080707</td>\n",
       "      <td>0.116132</td>\n",
       "      <td>0.070408</td>\n",
       "      <td>5.789687e-09</td>\n",
       "      <td>1.006968e-07</td>\n",
       "      <td>5.511108e-12</td>\n",
       "      <td>0.099182</td>\n",
       "      <td>71.424179</td>\n",
       "      <td>-168.027863</td>\n",
       "      <td>1598.270264</td>\n",
       "      <td>-374.637360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.197601</td>\n",
       "      <td>0.209846</td>\n",
       "      <td>0.208479</td>\n",
       "      <td>7.257671e-05</td>\n",
       "      <td>1.019616e-04</td>\n",
       "      <td>3.654962e-06</td>\n",
       "      <td>0.206515</td>\n",
       "      <td>79.227253</td>\n",
       "      <td>-100.980476</td>\n",
       "      <td>1637.834961</td>\n",
       "      <td>43.151689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.223239</td>\n",
       "      <td>0.229495</td>\n",
       "      <td>0.235907</td>\n",
       "      <td>1.237012e-03</td>\n",
       "      <td>1.502150e-03</td>\n",
       "      <td>3.526122e-04</td>\n",
       "      <td>0.234635</td>\n",
       "      <td>82.100246</td>\n",
       "      <td>-82.147526</td>\n",
       "      <td>1650.136169</td>\n",
       "      <td>142.068436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.249933</td>\n",
       "      <td>0.246463</td>\n",
       "      <td>0.252080</td>\n",
       "      <td>1.882479e-02</td>\n",
       "      <td>1.485101e-02</td>\n",
       "      <td>7.196977e-02</td>\n",
       "      <td>0.251901</td>\n",
       "      <td>84.318287</td>\n",
       "      <td>-71.274647</td>\n",
       "      <td>1666.600311</td>\n",
       "      <td>402.496101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.456576</td>\n",
       "      <td>0.353023</td>\n",
       "      <td>0.362429</td>\n",
       "      <td>3.300374e-01</td>\n",
       "      <td>1.768186e-01</td>\n",
       "      <td>2.284313e-01</td>\n",
       "      <td>0.327535</td>\n",
       "      <td>86.686356</td>\n",
       "      <td>-39.878021</td>\n",
       "      <td>1707.645020</td>\n",
       "      <td>919.184143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fe          Cr          Ni            Mn            Al  \\\n",
       "count  500.000000  500.000000  500.000000  5.000000e+02  5.000000e+02   \n",
       "mean     0.223816    0.227380    0.228819  3.304442e-02  1.863189e-02   \n",
       "std      0.049817    0.030970    0.036191  6.694506e-02  3.530871e-02   \n",
       "min      0.080707    0.116132    0.070408  5.789687e-09  1.006968e-07   \n",
       "25%      0.197601    0.209846    0.208479  7.257671e-05  1.019616e-04   \n",
       "50%      0.223239    0.229495    0.235907  1.237012e-03  1.502150e-03   \n",
       "75%      0.249933    0.246463    0.252080  1.882479e-02  1.485101e-02   \n",
       "max      0.456576    0.353023    0.362429  3.300374e-01  1.768186e-01   \n",
       "\n",
       "                 Cu          Co       E_M-M  \\\n",
       "count  5.000000e+02  500.000000  500.000000   \n",
       "mean   4.050260e-02    0.227805   81.367155   \n",
       "std    6.545965e-02    0.034336    3.386451   \n",
       "min    5.511108e-12    0.099182   71.424179   \n",
       "25%    3.654962e-06    0.206515   79.227253   \n",
       "50%    3.526122e-04    0.234635   82.100246   \n",
       "75%    7.196977e-02    0.251901   84.318287   \n",
       "max    2.284313e-01    0.327535   86.686356   \n",
       "\n",
       "       Gibbs free energy of oxide formation_Aver  \\\n",
       "count                                 500.000000   \n",
       "mean                                  -88.989191   \n",
       "std                                    30.019819   \n",
       "min                                  -168.027863   \n",
       "25%                                  -100.980476   \n",
       "50%                                   -82.147526   \n",
       "75%                                   -71.274647   \n",
       "max                                   -39.878021   \n",
       "\n",
       "       Energy of ionization second_Aver        Epit  \n",
       "count                        500.000000  500.000000  \n",
       "mean                        1651.587129  232.402195  \n",
       "std                           24.654049  280.525059  \n",
       "min                         1598.270264 -374.637360  \n",
       "25%                         1637.834961   43.151689  \n",
       "50%                         1650.136169  142.068436  \n",
       "75%                         1666.600311  402.496101  \n",
       "max                         1707.645020  919.184143  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"generated_samples_robust_feature.xlsx\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "29b4a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Epit'])\n",
    "y = df['Epit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a4ada9",
   "metadata": {},
   "source": [
    "# Surrogate Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "94a660b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "19ba8fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.to_numpy().reshape(-1, 1)).flatten()\n",
    "y_test_scaled = y_scaler.transform(y_test.to_numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fada6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobustNN(input_dim=X_train.shape[1])\n",
    "model = train_model(model, train_loader, test_loader, l1_lambda=0.02)\n",
    "preds, trues = evaluate_model(model, test_loader, y_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86eb45c",
   "metadata": {},
   "source": [
    "# Bayesian Optimization with Elements Composition Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dfa6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELEMENTS = ['Fe','Cr','Ni','Mn','Al','Cu','Co']\n",
    "lower = np.array([0.20, 0.20, 0.20, 0.00, 0.02, 0.00, 0.20], dtype=np.float32)\n",
    "upper = np.array([0.30, 0.35, 0.30, 0.00, 0.06, 0.00, 0.30], dtype=np.float32)\n",
    "\n",
    "SOFTMAX_T = 0.3\n",
    "BOX_PENALTY = 5e3        \n",
    "MN_CU_PENALTY = 5.0       \n",
    "FEASIBILITY_HARD = 1e6   \n",
    "\n",
    "def softmax(x, temp=1.0, axis=-1):\n",
    "    z = (x / temp) - np.max(x / temp, axis=axis, keepdims=True)\n",
    "    e = np.exp(z)\n",
    "    return e / e.sum(axis=axis, keepdims=True)\n",
    "\n",
    "def project_simplex_bounded(w, lo, hi):\n",
    "    x = w.copy()\n",
    "    x = np.clip(x, lo, hi)\n",
    "    s = x.sum()\n",
    "    if s != 0:\n",
    "        x = x / s\n",
    "        x = np.clip(x, lo, hi)\n",
    "        x = x / x.sum()\n",
    "    return x\n",
    "\n",
    "def composition_from_raw(r):\n",
    "    \"\"\"\n",
    "    r: [r_Fe, r_Cr, r_Ni, r_Mn, r_Al, r_Cu, r_Co]\n",
    "    return：x_comp（sum = 1)，boolean\n",
    "    \"\"\"\n",
    "    w = softmax(np.asarray(r, dtype=np.float32), temp=SOFTMAX_T)\n",
    "    x = project_simplex_bounded(w, lower, upper)\n",
    "\n",
    "    if lower.sum() > 1 + 1e-9 or upper.sum() < 1 - 1e-9:\n",
    "        return x, False  \n",
    "    return x, True\n",
    "\n",
    "def black_box_function_dirichlet(r_Fe, r_Cr, r_Ni, r_Mn, r_Al, r_Cu, r_Co):\n",
    "    r = [r_Fe, r_Cr, r_Ni, r_Mn, r_Al, r_Cu, r_Co]\n",
    "    x_comp, feas_ok = composition_from_raw(r)\n",
    "    below = np.maximum(0.0, lower - x_comp)\n",
    "    above = np.maximum(0.0, x_comp - upper)\n",
    "    box_violation = below.sum() + above.sum()\n",
    "    penalty = BOX_PENALTY * box_violation\n",
    "    if not feas_ok:\n",
    "        return -FEASIBILITY_HARD\n",
    "    Mn = x_comp[ELEMENTS.index('Mn')]\n",
    "    Cu = x_comp[ELEMENTS.index('Cu')]\n",
    "    penalty += MN_CU_PENALTY * (Mn + Cu)\n",
    "\n",
    "    x_df = pd.DataFrame([x_comp], columns=ELEMENTS)\n",
    "    x_scaled = scaler.transform(x_df)\n",
    "    x_tensor = torch.tensor(x_scaled, dtype=torch.float32)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_scaled = model(x_tensor).item()\n",
    "    y_real = y_scaler.inverse_transform([[y_scaled]])[0][0]\n",
    "\n",
    "    return y_real - penalty\n",
    "\n",
    "pbounds_raw = {\n",
    "    'r_Fe': (0.0, 1.0),\n",
    "    'r_Cr': (0.0, 1.0),\n",
    "    'r_Ni': (0.0, 1.0),\n",
    "    'r_Mn': (0.0, 1.0),\n",
    "    'r_Al': (0.0, 1.0),\n",
    "    'r_Cu': (0.0, 1.0),\n",
    "    'r_Co': (0.0, 1.0),\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=black_box_function_dirichlet,\n",
    "    pbounds=pbounds_raw,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9fd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   r_Fe    |   r_Cr    |   r_Ni    |   r_Mn    |   r_Al    |   r_Cu    |   r_Co    |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m1098.5967\u001b[39m | \u001b[39m0.3745401\u001b[39m | \u001b[39m0.9507143\u001b[39m | \u001b[39m0.7319939\u001b[39m | \u001b[39m0.5986584\u001b[39m | \u001b[39m0.1560186\u001b[39m | \u001b[39m0.1559945\u001b[39m | \u001b[39m0.0580836\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m765.53136\u001b[39m | \u001b[39m0.8661761\u001b[39m | \u001b[39m0.6011150\u001b[39m | \u001b[39m0.7080725\u001b[39m | \u001b[39m0.0205844\u001b[39m | \u001b[39m0.9699098\u001b[39m | \u001b[39m0.8324426\u001b[39m | \u001b[39m0.2123391\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m635.60043\u001b[39m | \u001b[39m0.1818249\u001b[39m | \u001b[39m0.1834045\u001b[39m | \u001b[39m0.3042422\u001b[39m | \u001b[39m0.5247564\u001b[39m | \u001b[39m0.4319450\u001b[39m | \u001b[39m0.2912291\u001b[39m | \u001b[39m0.6118528\u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m767.64367\u001b[39m | \u001b[39m0.1394938\u001b[39m | \u001b[39m0.2921446\u001b[39m | \u001b[39m0.3663618\u001b[39m | \u001b[39m0.4560699\u001b[39m | \u001b[39m0.7851759\u001b[39m | \u001b[39m0.1996737\u001b[39m | \u001b[39m0.5142344\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m581.59655\u001b[39m | \u001b[39m0.5924145\u001b[39m | \u001b[39m0.0464504\u001b[39m | \u001b[39m0.6075448\u001b[39m | \u001b[39m0.1705241\u001b[39m | \u001b[39m0.0650515\u001b[39m | \u001b[39m0.9488855\u001b[39m | \u001b[39m0.9656320\u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m710.76810\u001b[39m | \u001b[39m0.8083973\u001b[39m | \u001b[39m0.3046137\u001b[39m | \u001b[39m0.0976721\u001b[39m | \u001b[39m0.6842330\u001b[39m | \u001b[39m0.4401524\u001b[39m | \u001b[39m0.1220382\u001b[39m | \u001b[39m0.4951769\u001b[39m |\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m1155.9052\u001b[39m | \u001b[35m0.0343885\u001b[39m | \u001b[35m0.9093204\u001b[39m | \u001b[35m0.2587799\u001b[39m | \u001b[35m0.6625222\u001b[39m | \u001b[35m0.3117110\u001b[39m | \u001b[35m0.5200680\u001b[39m | \u001b[35m0.5467102\u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m851.51489\u001b[39m | \u001b[39m0.1848544\u001b[39m | \u001b[39m0.9695846\u001b[39m | \u001b[39m0.7751328\u001b[39m | \u001b[39m0.9394989\u001b[39m | \u001b[39m0.8948273\u001b[39m | \u001b[39m0.5978999\u001b[39m | \u001b[39m0.9218742\u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m617.28687\u001b[39m | \u001b[39m0.0884925\u001b[39m | \u001b[39m0.1959828\u001b[39m | \u001b[39m0.0452272\u001b[39m | \u001b[39m0.3253303\u001b[39m | \u001b[39m0.3886772\u001b[39m | \u001b[39m0.2713490\u001b[39m | \u001b[39m0.8287375\u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m617.28687\u001b[39m | \u001b[39m0.3567533\u001b[39m | \u001b[39m0.2809345\u001b[39m | \u001b[39m0.5426960\u001b[39m | \u001b[39m0.1409242\u001b[39m | \u001b[39m0.8021969\u001b[39m | \u001b[39m0.0745506\u001b[39m | \u001b[39m0.9868869\u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m1144.5765\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.2782449\u001b[39m | \u001b[39m0.9411026\u001b[39m | \u001b[39m0.2776665\u001b[39m | \u001b[39m0.5418641\u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m1108.1607\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0943167\u001b[39m | \u001b[39m0.1780597\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.5447410\u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m1095.8517\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.9934966\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.3785442\u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m1154.1369\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.4776399\u001b[39m | \u001b[39m0.9258402\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m1072.9216\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.4635714\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m978.97209\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.7129611\u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m910.19460\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.7905145\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m1039.5734\u001b[39m | \u001b[39m0.6506395\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m1156.4473\u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m0.8542533\u001b[39m | \u001b[35m0.2798688\u001b[39m | \u001b[35m0.4001410\u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m847.66626\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.4917254\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m1154.1369\u001b[39m | \u001b[39m0.2787353\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.5514212\u001b[39m | \u001b[39m0.4517674\u001b[39m | \u001b[39m0.3675944\u001b[39m | \u001b[39m0.1633243\u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m1154.1369\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.5654638\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.6896363\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m768.77297\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[35m24       \u001b[39m | \u001b[35m1161.7507\u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m0.3359807\u001b[39m | \u001b[35m0.4908994\u001b[39m | \u001b[35m0.1936641\u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m0.0      \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m1095.8517\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.7055987\u001b[39m | \u001b[39m0.6801579\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.5859328\u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m1154.1369\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.3661381\u001b[39m | \u001b[39m0.5998719\u001b[39m | \u001b[39m0.5759216\u001b[39m | \u001b[39m0.2929695\u001b[39m | \u001b[39m0.2510147\u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m986.69392\u001b[39m | \u001b[39m0.8365246\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m1104.9784\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m829.37759\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m1095.8517\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.8028088\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m825.88110\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.5763448\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m1023.3359\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.7141830\u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m1097.8576\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.2725954\u001b[39m | \u001b[39m0.6684703\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.3824893\u001b[39m | \u001b[39m0.3047360\u001b[39m |\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m1154.1369\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.4497227\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m1154.1369\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.4138251\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "=============================================================================================================\n",
      "\n",
      "最优合金元素比例（和=1）：\n",
      "Fe: 0.2010\n",
      "Cr: 0.3504\n",
      "Ni: 0.2010\n",
      "Mn: 0.0000\n",
      "Al: 0.0466\n",
      "Cu: 0.0000\n",
      "Co: 0.2010\n",
      "\n",
      "目标函数（含惩罚）最大值: 1161.7508\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(init_points=10, n_iter=25)\n",
    "best_params = optimizer.max['params']\n",
    "r_star = [best_params['r_'+e] for e in ELEMENTS]\n",
    "x_star, _ = composition_from_raw(r_star)\n",
    "\n",
    "print(\"\\n最优合金元素比例（和=1）：\")\n",
    "for ele, val in zip(ELEMENTS, x_star):\n",
    "    print(f\"{ele}: {val:.4f}\")\n",
    "\n",
    "print(f\"\\n目标函数（含惩罚）最大值: {optimizer.max['target']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa06e8d",
   "metadata": {},
   "source": [
    "# Bayesian Optimization with Additional Calculated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b515d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELEMENTS = ['Fe','Cr','Ni','Mn','Al','Cu','Co']\n",
    "EXTRA_COLS = ['E_M-M', 'Gibbs free energy of oxide formation_Aver', 'Energy of ionization second_Aver'] \n",
    "lower = np.array([0.20, 0.20, 0.20, 0.00, 0.02, 0.00, 0.20], dtype=np.float32)\n",
    "upper = np.array([0.30, 0.35, 0.30, 0.00, 0.06, 0.00, 0.30], dtype=np.float32)\n",
    "\n",
    "SOFTMAX_T = 0.3\n",
    "BOX_PENALTY = 5e3         \n",
    "MN_CU_PENALTY = 100       \n",
    "FEASIBILITY_HARD = 1e6    \n",
    "\n",
    "K_NEIGHBORS = 15\n",
    "_nn = NearestNeighbors(n_neighbors=K_NEIGHBORS, metric='euclidean')\n",
    "_nn.fit(X_train[ELEMENTS].to_numpy(dtype=np.float32))\n",
    "\n",
    "def infer_extras_by_knn(x_comp: np.ndarray) -> np.ndarray:\n",
    "    dist, idx = _nn.kneighbors(x_comp.reshape(1, -1), return_distance=True)\n",
    "    w = 1.0 / (dist + 1e-6)        \n",
    "    w = (w / w.sum()).ravel()\n",
    "    extras = (X_train.iloc[idx[0]][EXTRA_COLS]\n",
    "              .to_numpy(dtype=np.float32) * w[:, None]).sum(axis=0)\n",
    "    return extras\n",
    "\n",
    "def build_row_from_comp(x_comp: np.ndarray) -> pd.DataFrame:\n",
    "    extras = infer_extras_by_knn(x_comp)\n",
    "    row = np.concatenate([x_comp, extras]).reshape(1, -1)\n",
    "    return pd.DataFrame(row, columns=ELEMENTS + EXTRA_COLS)\n",
    "\n",
    "def softmax(x, temp=1.0, axis=-1):\n",
    "    z = (x / temp) - np.max(x / temp, axis=axis, keepdims=True)\n",
    "    e = np.exp(z)\n",
    "    return e / e.sum(axis=axis, keepdims=True)\n",
    "\n",
    "def project_simplex_bounded(w, lo, hi):\n",
    "    x = w.copy()\n",
    "    x = np.clip(x, lo, hi)\n",
    "    s = x.sum()\n",
    "    if s != 0:\n",
    "        x = x / s\n",
    "        x = np.clip(x, lo, hi)\n",
    "        x = x / x.sum()\n",
    "    return x\n",
    "\n",
    "def composition_from_raw(r):\n",
    "    w = softmax(np.asarray(r, dtype=np.float32), temp=SOFTMAX_T)\n",
    "    x = project_simplex_bounded(w, lower, upper)\n",
    "    if lower.sum() > 1 + 1e-9 or upper.sum() < 1 - 1e-9:\n",
    "        return x, False\n",
    "    return x, True\n",
    "\n",
    "def black_box_function_dirichlet(r_Fe, r_Cr, r_Ni, r_Mn, r_Al, r_Cu, r_Co):\n",
    "    r = [r_Fe, r_Cr, r_Ni, r_Mn, r_Al, r_Cu, r_Co]\n",
    "    x_comp, feas_ok = composition_from_raw(r)\n",
    "\n",
    "    below = np.maximum(0.0, lower - x_comp)\n",
    "    above = np.maximum(0.0, x_comp - upper)\n",
    "    box_violation = below.sum() + above.sum()\n",
    "    penalty = BOX_PENALTY * box_violation\n",
    "    if not feas_ok:\n",
    "        return -FEASIBILITY_HARD\n",
    "\n",
    "    Mn = x_comp[ELEMENTS.index('Mn')]\n",
    "    Cu = x_comp[ELEMENTS.index('Cu')]\n",
    "    penalty += MN_CU_PENALTY * (Mn + Cu)\n",
    "\n",
    "    x_df = build_row_from_comp(x_comp)                    \n",
    "    x_scaled = scaler.transform(x_df)\n",
    "    x_tensor = torch.tensor(x_scaled, dtype=torch.float32)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_scaled = model(x_tensor).item()\n",
    "    y_real = y_scaler.inverse_transform([[y_scaled]])[0][0]\n",
    "\n",
    "    return y_real - penalty\n",
    "\n",
    "pbounds_raw = {\n",
    "    'r_Fe': (0.0, 1.0),\n",
    "    'r_Cr': (0.0, 1.0),\n",
    "    'r_Ni': (0.0, 1.0),\n",
    "    'r_Mn': (0.0, 1.0),\n",
    "    'r_Al': (0.0, 1.0),\n",
    "    'r_Cu': (0.0, 1.0),\n",
    "    'r_Co': (0.0, 1.0),\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=black_box_function_dirichlet,\n",
    "    pbounds=pbounds_raw,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "599fba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   r_Fe    |   r_Cr    |   r_Ni    |   r_Mn    |   r_Al    |   r_Cu    |   r_Co    |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m668.63409\u001b[39m | \u001b[39m0.3745401\u001b[39m | \u001b[39m0.9507143\u001b[39m | \u001b[39m0.7319939\u001b[39m | \u001b[39m0.5986584\u001b[39m | \u001b[39m0.1560186\u001b[39m | \u001b[39m0.1559945\u001b[39m | \u001b[39m0.0580836\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m419.76615\u001b[39m | \u001b[39m0.8661761\u001b[39m | \u001b[39m0.6011150\u001b[39m | \u001b[39m0.7080725\u001b[39m | \u001b[39m0.0205844\u001b[39m | \u001b[39m0.9699098\u001b[39m | \u001b[39m0.8324426\u001b[39m | \u001b[39m0.2123391\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m537.57606\u001b[39m | \u001b[39m0.1818249\u001b[39m | \u001b[39m0.1834045\u001b[39m | \u001b[39m0.3042422\u001b[39m | \u001b[39m0.5247564\u001b[39m | \u001b[39m0.4319450\u001b[39m | \u001b[39m0.2912291\u001b[39m | \u001b[39m0.6118528\u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m491.86251\u001b[39m | \u001b[39m0.1394938\u001b[39m | \u001b[39m0.2921446\u001b[39m | \u001b[39m0.3663618\u001b[39m | \u001b[39m0.4560699\u001b[39m | \u001b[39m0.7851759\u001b[39m | \u001b[39m0.1996737\u001b[39m | \u001b[39m0.5142344\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m469.09721\u001b[39m | \u001b[39m0.5924145\u001b[39m | \u001b[39m0.0464504\u001b[39m | \u001b[39m0.6075448\u001b[39m | \u001b[39m0.1705241\u001b[39m | \u001b[39m0.0650515\u001b[39m | \u001b[39m0.9488855\u001b[39m | \u001b[39m0.9656320\u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m218.04945\u001b[39m | \u001b[39m0.8083973\u001b[39m | \u001b[39m0.3046137\u001b[39m | \u001b[39m0.0976721\u001b[39m | \u001b[39m0.6842330\u001b[39m | \u001b[39m0.4401524\u001b[39m | \u001b[39m0.1220382\u001b[39m | \u001b[39m0.4951769\u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m595.74094\u001b[39m | \u001b[39m0.0343885\u001b[39m | \u001b[39m0.9093204\u001b[39m | \u001b[39m0.2587799\u001b[39m | \u001b[39m0.6625222\u001b[39m | \u001b[39m0.3117110\u001b[39m | \u001b[39m0.5200680\u001b[39m | \u001b[39m0.5467102\u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m574.64557\u001b[39m | \u001b[39m0.1848544\u001b[39m | \u001b[39m0.9695846\u001b[39m | \u001b[39m0.7751328\u001b[39m | \u001b[39m0.9394989\u001b[39m | \u001b[39m0.8948273\u001b[39m | \u001b[39m0.5978999\u001b[39m | \u001b[39m0.9218742\u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m537.57606\u001b[39m | \u001b[39m0.0884925\u001b[39m | \u001b[39m0.1959828\u001b[39m | \u001b[39m0.0452272\u001b[39m | \u001b[39m0.3253303\u001b[39m | \u001b[39m0.3886772\u001b[39m | \u001b[39m0.2713490\u001b[39m | \u001b[39m0.8287375\u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m537.57606\u001b[39m | \u001b[39m0.3567533\u001b[39m | \u001b[39m0.2809345\u001b[39m | \u001b[39m0.5426960\u001b[39m | \u001b[39m0.1409242\u001b[39m | \u001b[39m0.8021969\u001b[39m | \u001b[39m0.0745506\u001b[39m | \u001b[39m0.9868869\u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m536.29553\u001b[39m | \u001b[39m0.7290071\u001b[39m | \u001b[39m0.2741361\u001b[39m | \u001b[39m0.4933262\u001b[39m | \u001b[39m0.3216106\u001b[39m | \u001b[39m0.6829772\u001b[39m | \u001b[39m0.5845955\u001b[39m | \u001b[39m0.8650811\u001b[39m |\n",
      "| \u001b[35m12       \u001b[39m | \u001b[35m703.18405\u001b[39m | \u001b[35m0.1218498\u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m0.7200612\u001b[39m | \u001b[35m0.6488503\u001b[39m | \u001b[35m0.2149720\u001b[39m | \u001b[35m0.3341187\u001b[39m | \u001b[35m0.2828315\u001b[39m |\n",
      "| \u001b[35m13       \u001b[39m | \u001b[35m724.53698\u001b[39m | \u001b[35m0.3466573\u001b[39m | \u001b[35m0.9335117\u001b[39m | \u001b[35m0.0011094\u001b[39m | \u001b[35m0.1207774\u001b[39m | \u001b[35m0.7935022\u001b[39m | \u001b[35m0.0399502\u001b[39m | \u001b[35m0.8355217\u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m218.50342\u001b[39m | \u001b[39m0.9604344\u001b[39m | \u001b[39m0.0749623\u001b[39m | \u001b[39m0.0640585\u001b[39m | \u001b[39m0.7565628\u001b[39m | \u001b[39m0.3583979\u001b[39m | \u001b[39m0.7321421\u001b[39m | \u001b[39m0.0139313\u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m686.99720\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.5981314\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.2333711\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.6638724\u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m494.99421\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.7716206\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.8473767\u001b[39m |\n",
      "| \u001b[35m17       \u001b[39m | \u001b[35m740.15455\u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m0.1514117\u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m0.9195061\u001b[39m | \u001b[35m0.4577689\u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m520.93650\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.9812277\u001b[39m | \u001b[39m0.0055137\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.5162923\u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m724.53698\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.4452664\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m590.26480\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.4259725\u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m724.53698\u001b[39m | \u001b[39m0.4526353\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.3163717\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.4892861\u001b[39m | \u001b[39m0.4216835\u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m672.58069\u001b[39m | \u001b[39m0.4901358\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m659.76239\u001b[39m | \u001b[39m0.9619461\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.1012340\u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[35m24       \u001b[39m | \u001b[35m777.88964\u001b[39m | \u001b[35m0.2797897\u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m0.5526592\u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m590.75401\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.5694483\u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m491.86251\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m764.83271\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.2931510\u001b[39m | \u001b[39m0.3860172\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m397.78431\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.6951900\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m724.53698\u001b[39m | \u001b[39m0.1979303\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.4254443\u001b[39m | \u001b[39m0.2079395\u001b[39m | \u001b[39m0.6384457\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[35m30       \u001b[39m | \u001b[35m905.50939\u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m0.0      \u001b[39m | \u001b[35m1.0      \u001b[39m | \u001b[35m1.0      \u001b[39m |\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m881.58638\u001b[39m | \u001b[39m0.4633603\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m739.79552\u001b[39m | \u001b[39m0.1466272\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.5394597\u001b[39m |\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m880.55314\u001b[39m | \u001b[39m0.1053833\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.4439900\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m876.60211\u001b[39m | \u001b[39m0.1748637\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.1313203\u001b[39m | \u001b[39m0.4132115\u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m862.41394\u001b[39m | \u001b[39m0.1097377\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m0.1316314\u001b[39m | \u001b[39m0.0817506\u001b[39m | \u001b[39m0.3119536\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "=============================================================================================================\n",
      "\n",
      "最优合金元素比例（归一化后，和=1）：\n",
      "Fe: 0.2030\n",
      "Cr: 0.3230\n",
      "Ni: 0.2030\n",
      "Mn: 0.0000\n",
      "Al: 0.0203\n",
      "Cu: 0.0000\n",
      "Co: 0.2507\n",
      "\n",
      "目标函数（含惩罚）最大值: 905.5094\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(init_points=10, n_iter=25)\n",
    "best_params = optimizer.max['params']\n",
    "r_star = [best_params['r_'+e] for e in ELEMENTS]\n",
    "x_star, _ = composition_from_raw(r_star)\n",
    "\n",
    "print(\"\\n最优合金元素比例（归一化后，和=1）：\")\n",
    "for ele, val in zip(ELEMENTS, x_star):\n",
    "    print(f\"{ele}: {val:.4f}\")\n",
    "\n",
    "print(f\"\\n目标函数（含惩罚）最大值: {optimizer.max['target']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "505eb138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "对应的三个额外特征（由 kNN 条件均值推断）：\n",
      "E_M-M: 83.9472\n",
      "Gibbs free energy of oxide formation_Aver: -97.8205\n",
      "Energy of ionization second_Aver: 1645.3637\n"
     ]
    }
   ],
   "source": [
    "extras_star = infer_extras_by_knn(np.array(x_star))\n",
    "print(\"\\n对应的三个额外特征（由 kNN 条件均值推断）：\")\n",
    "for col, val in zip(EXTRA_COLS, extras_star):\n",
    "    print(f\"{col}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcdd6c",
   "metadata": {},
   "source": [
    "# MPEA1 and MPEA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c4f07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hea_1_composition = {\n",
    "    'Fe': 0.2128,\n",
    "    'Cr': 0.3191,\n",
    "    'Ni': 0.2127,\n",
    "    'Mn': 0.00,\n",
    "    'Al': 0.0426,\n",
    "    'Cu': 0.00,\n",
    "    'Co': 0.2127,\n",
    "}\n",
    "hea_2_composition = {\n",
    "    'Fe': 0.202,\n",
    "    'Cr': 0.3535,\n",
    "    'Ni': 0.202,\n",
    "    'Mn': 0.00,\n",
    "    'Al': 0.0404,\n",
    "    'Cu': 0.00,\n",
    "    'Co': 0.2021,\n",
    "}\n",
    "hea_1_full = {\n",
    "    'Fe': 0.2128,\n",
    "    'Cr': 0.3191,\n",
    "    'Ni': 0.2127,\n",
    "    'Mn': 0.00,\n",
    "    'Al': 0.0426,\n",
    "    'Cu': 0.00,\n",
    "    'Co': 0.2127,\n",
    "    'E_M-M': 85.0737,\n",
    "    'Gibbs free energy of oxide formation_Aver': -142.11425,\n",
    "    'Energy of ionization second_Aver': 1640.7241,\n",
    "}\n",
    "hea_2_full = {\n",
    "    'Fe': 0.202,\n",
    "    'Cr': 0.3535,\n",
    "    'Ni': 0.202,\n",
    "    'Mn': 0.00,\n",
    "    'Al': 0.0404,\n",
    "    'Cu': 0.00,\n",
    "    'Co': 0.2021,\n",
    "    'E_M-M': 85.736856,\n",
    "    'Gibbs free energy of oxide formation_Aver': -152.15142,\n",
    "    'Energy of ionization second_Aver': 1638.2741,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee4fc7",
   "metadata": {},
   "source": [
    "# Forward Prediction Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "10250926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Epit for HEA-1: 842.5880\n"
     ]
    }
   ],
   "source": [
    "tmp = pd.DataFrame([hea_1_composition])[X_train.columns]\n",
    "tmp_scaled = scaler.transform(tmp)\n",
    "tmp_tensor = torch.tensor(tmp_scaled, dtype=torch.float32)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_scaled = model(tmp_tensor).item()\n",
    "y_real = y_scaler.inverse_transform([[y_scaled]])[0][0]\n",
    "print(f\"Predicted Epit for HEA-1: {y_real:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "34f5e38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Epit for HEA-2: 1024.6275\n"
     ]
    }
   ],
   "source": [
    "tmp_1 = pd.DataFrame([hea_2_composition])[X_train.columns]\n",
    "tmp_1_scaled = scaler.transform(tmp_1)\n",
    "tmp_1_tensor = torch.tensor(tmp_1_scaled, dtype=torch.float32)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_1_scaled = model(tmp_1_tensor).item()\n",
    "y_1_real = y_scaler.inverse_transform([[y_1_scaled]])[0][0]\n",
    "print(f\"Predicted Epit for HEA-2: {y_1_real:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9035db",
   "metadata": {},
   "source": [
    "# Forward Prediction Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b132d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Epit for HEA-1: 745.4340\n"
     ]
    }
   ],
   "source": [
    "tmp = pd.DataFrame([hea_1_full])[X_train.columns]\n",
    "tmp_scaled = scaler.transform(tmp)\n",
    "tmp_tensor = torch.tensor(tmp_scaled, dtype=torch.float32)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_scaled = model(tmp_tensor).item()\n",
    "y_real = y_scaler.inverse_transform([[y_scaled]])[0][0]\n",
    "print(f\"Predicted Epit for HEA-1: {y_real:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6f9a1581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Epit for HEA-2: 832.5305\n"
     ]
    }
   ],
   "source": [
    "tmp_1 = pd.DataFrame([hea_2_full])[X_train.columns]\n",
    "tmp_1_scaled = scaler.transform(tmp_1)\n",
    "tmp_1_tensor = torch.tensor(tmp_1_scaled, dtype=torch.float32)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_1_scaled = model(tmp_1_tensor).item()\n",
    "y_1_real = y_scaler.inverse_transform([[y_1_scaled]])[0][0]\n",
    "print(f\"Predicted Epit for HEA-2: {y_1_real:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
